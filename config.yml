# GPUS and distributed training setting
gpus: "0"
distributed: False
workers: 8

# logging
wandb: True
project_name: GNN_UCM_SMALL
log_interval: 1
val_check_interval: 0.5 # run validation twice per epoch
checkpoint: ./gnn_aug_max_pos_sweep
version: 0.4

dataset_dir: ./datasets
dataset: UCM # AID, NWPU, PNET, UCM
seed: 420
use_transform: True

val_sets: ["UCM"] # run test on same dataset, you can add more than one dataset
label_txt: multilabels_ucm.txt # FUll path
sep: '\t' # \t for ucm and , for aid

learning_rate: !!float 0.005583
batch_size: 6
max_epochs: 5

num_classes: 17
model_name: vgg16 # timm create model: resnet18, vgg16
pretrained: True
model_dir: "/home/ncl/vlle/linh/vgg16/UCM-epoch=0-valid_precision=0.82.ckpt"
resume: False

optimizer: Adam # Adam, AdamW, RMSProp, SGD
weight_decay: !!float 0.001224
# for adam and adamw
eps_adam: !!float 8.755e-9
beta_1: 1.28
beta_2: 1.759
# for rmsprop
eps_rms: !!float 1e-8
alpha: 1.642

loss_function: BCE # MSE, NL, CE, HE, KL, BCE
augmentation: True # apply simple augmentation to dataset (horizontol flip, color jitter)

# test
run_test: False

# Dynamic model config
topk: 21
num_seg: 91
aggr: 'max' #'max', 'mean'
cat: False
with_pos: True
